\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Bayesian inference}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Priors}{3}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Markov chain Monte Carlo (MCMC) in ADMB}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Workflow}{3}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}MCMC Phases}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Output files}{4}{subsection.4.3}}
\newlabel{sec:outfiles}{{4.3}{4}{Output files}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Meta data: The hst file}{4}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Parameter draws: The psv file}{5}{subsubsection.4.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Derived quantity draws}{5}{subsubsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Convergence diagnostics}{6}{subsection.4.4}}
\newlabel{sec:diag}{{4.4}{6}{Convergence diagnostics}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Resuming a chain}{6}{subsection.4.5}}
\newlabel{sec:restart}{{4.5}{6}{Resuming a chain}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Starting values}{6}{subsection.4.6}}
\newlabel{sec:startvals}{{4.6}{6}{Starting values}{subsection.4.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter draws from the "simple" example. The "first" columns are saved parameter draws from a short chain, $Nout=10$. The values from the "resumed" chain were created using the \texttt  {-mcr} option, where they pick up from where the "first" chain left off, $Nout=20$. The values shown from the "long" chain were completed in a single run (not resumed with \texttt  {-mcr} and set to match the total number of iterations and thinning rate from the "reduced" chain.}}{7}{table.1}}
\newlabel{tab:mcr_table}{{1}{7}{Parameter draws from the "simple" example. The "first" columns are saved parameter draws from a short chain, $Nout=10$. The values from the "resumed" chain were created using the \texttt {-mcr} option, where they pick up from where the "first" chain left off, $Nout=20$. The values shown from the "long" chain were completed in a single run (not resumed with \texttt {-mcr} and set to match the total number of iterations and thinning rate from the "reduced" chain}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Metropolis-Hastings MCMC}{7}{section.5}}
\newlabel{sec:MH}{{5}{7}{Metropolis-Hastings MCMC}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Algorithm}{7}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}MCMC Arguments}{8}{subsection.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces ADMB runtime arguments for the Metropolis-Hastings MCMC}}{8}{table.2}}
\newlabel{tab:mh_args}{{2}{8}{ADMB runtime arguments for the Metropolis-Hastings MCMC}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Console output}{8}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Example MCMC}{8}{subsection.5.4}}
\citation{roberts2001}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The samples from a simple model with \texttt  {mcsave}=1. Note the high autocorrelation of both parameters.The red ellipses show the estimated pairwise parameter covariances, and the red point the MPD.}}{9}{figure.1}}
\newlabel{fig:simple1}{{1}{9}{The samples from a simple model with \texttt {mcsave}=1. Note the high autocorrelation of both parameters.The red ellipses show the estimated pairwise parameter covariances, and the red point the MPD}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Tuning the MH algorithm}{9}{subsection.5.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}Thinning rate}{9}{subsubsection.5.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Optimize the acceptance rate}{9}{subsubsection.5.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The samples from a simple model with \texttt  {mcsave}=100. Note the negligible autocorrelation of both parameters.The red ellipses show the estimated pairwise parameter covariances, and the red point the MPD.}}{10}{figure.2}}
\newlabel{fig:simple2}{{2}{10}{The samples from a simple model with \texttt {mcsave}=100. Note the negligible autocorrelation of both parameters.The red ellipses show the estimated pairwise parameter covariances, and the red point the MPD}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.3}mcprobe}{10}{subsubsection.5.5.3}}
\newlabel{sec:mcprobe}{{5.5.3}{10}{mcprobe}{subsubsection.5.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.4}mcrb}{10}{subsubsection.5.5.4}}
\newlabel{sec:mcrb}{{5.5.4}{10}{mcrb}{subsubsection.5.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example of fat-tailed proposal values for a parameter for the \texttt  {mcprobe} option compared to the default proposal.}}{11}{figure.3}}
\newlabel{fig:mcgrope_example}{{3}{11}{Example of fat-tailed proposal values for a parameter for the \texttt {mcprobe} option compared to the default proposal}{figure.3}{}}
\citation{brooks2011}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The effect of \texttt  {mcrb} on a variety of correlations between two hypothetical parameters. Note that the effect of setting $N=9$ depends on the original correlation.}}{12}{figure.4}}
\newlabel{fig:mcrb}{{4}{12}{The effect of \texttt {mcrb} on a variety of correlations between two hypothetical parameters. Note that the effect of setting $N=9$ depends on the original correlation}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.5}User-supplied covariance matrix}{12}{subsubsection.5.5.5}}
\newlabel{sec:user.cov}{{5.5.5}{12}{User-supplied covariance matrix}{subsubsection.5.5.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Hybrid MCMC}{12}{section.6}}
\newlabel{sec:hybrid}{{6}{12}{Hybrid MCMC}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Algorithm}{13}{subsection.6.1}}
\newlabel{eq:motion}{{2}{13}{Algorithm}{equation.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Leapfrog trajectories for different sets of tuning parameters. The posterior surface is shown as contours, and the posterior mode as a red point. The filled black point is the starting point, and the arrows show the trajectory of the leapfrog steps, ending at the open circle representing the proposed set of parameters.}}{14}{figure.5}}
\newlabel{fig:hybrid_grid_trace}{{5}{14}{Leapfrog trajectories for different sets of tuning parameters. The posterior surface is shown as contours, and the posterior mode as a red point. The filled black point is the starting point, and the arrows show the trajectory of the leapfrog steps, ending at the open circle representing the proposed set of parameters}{figure.5}{}}
\citation{brooks2011}
\citation{brooks2011}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Leapfrog projections for different random draws from $U$.}}{15}{figure.6}}
\newlabel{fig:hybrid_seeds}{{6}{15}{Leapfrog projections for different random draws from $U$}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Arguments}{15}{subsection.6.2}}
\citation{brooks2011}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces ADMB runtime arguments for the hybrid MCMC}}{16}{table.3}}
\newlabel{tab:hy_args}{{3}{16}{ADMB runtime arguments for the hybrid MCMC}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Tuning the hybrid algorithm}{16}{subsection.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The autocorrelation of the parameter $a$ from the simple model across different tuning parameters of the hybrid method.}}{17}{figure.7}}
\newlabel{fig:hybrid_grid_acf}{{7}{17}{The autocorrelation of the parameter $a$ from the simple model across different tuning parameters of the hybrid method}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}An example with non-linear posterior}{17}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The logistic model with 1 in 100 samples saved using the MH algorithm and estimated covariance matrix (red ellipse).}}{18}{figure.8}}
\newlabel{fig:logistic_mh}{{8}{18}{The logistic model with 1 in 100 samples saved using the MH algorithm and estimated covariance matrix (red ellipse)}{figure.8}{}}
\bibstyle{unsrt}
\bibdata{admb_guide}
\bibcite{roberts2001}{1}
\bibcite{brooks2011}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The logistic model with 1 in 100 samples saved using the MH algorithm and empirical covariance matrix (blue ellipse). Note the improvement in acf compared to \ref  {fig:logistic_mh}.}}{19}{figure.9}}
\newlabel{fig:logistic_mh2}{{9}{19}{The logistic model with 1 in 100 samples saved using the MH algorithm and empirical covariance matrix (blue ellipse). Note the improvement in acf compared to \ref {fig:logistic_mh}}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The logistic model with 1 in 100 samples saved using the MH algorithm and empirical covariance matrix (blue ellipse). Note the improvement in acf compared to \ref  {fig:logistic_mh}.}}{20}{figure.10}}
\newlabel{fig:logistic_mh2}{{10}{20}{The logistic model with 1 in 100 samples saved using the MH algorithm and empirical covariance matrix (blue ellipse). Note the improvement in acf compared to \ref {fig:logistic_mh}}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The logistic model using the hybrid method with default tuning parameters and the estimated covariance matrix (red ellipse).}}{20}{figure.11}}
\newlabel{fig:logistic_hy}{{11}{20}{The logistic model using the hybrid method with default tuning parameters and the estimated covariance matrix (red ellipse)}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The logistic model using the hybrid method with default tuning parameters and the empirical covariance matrix (blue ellipse).}}{21}{figure.12}}
\newlabel{fig:logistic_hy2}{{12}{21}{The logistic model using the hybrid method with default tuning parameters and the empirical covariance matrix (blue ellipse)}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The logistic model using the hybrid method and \texttt  {hyeps 0.05} and \texttt  {hynstep 100} for tuning parameters and the empirical covariance matrix (blue ellipse).}}{21}{figure.13}}
\newlabel{fig:logistic_hy3}{{13}{21}{The logistic model using the hybrid method and \texttt {hyeps 0.05} and \texttt {hynstep 100} for tuning parameters and the empirical covariance matrix (blue ellipse)}{figure.13}{}}
